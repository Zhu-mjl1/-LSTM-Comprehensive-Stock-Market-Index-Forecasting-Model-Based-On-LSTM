{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a55d1846",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T19:20:17.654631Z",
     "start_time": "2024-05-16T19:20:00.909370Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Training Loss: 0.00092, Validation Loss: 0.00070\n",
      "Epoch 20, Training Loss: 0.00060, Validation Loss: 0.00049\n",
      "Epoch 30, Training Loss: 0.00053, Validation Loss: 0.00049\n",
      "Epoch 40, Training Loss: 0.00049, Validation Loss: 0.00049\n",
      "Epoch 50, Training Loss: 0.00048, Validation Loss: 0.00045\n",
      "Early stopping at epoch 52\n",
      "Test Loss: 0.00070\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import yfinance as yf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "ticker = \"000001.SS\"\n",
    "stock = yf.Ticker(ticker)\n",
    "data = stock.history(start=\"2010-01-01\", end=\"2024-05-10\")\n",
    "\n",
    "# 过滤数据，只包含交易日\n",
    "data = data[data['Volume'] > 0]\n",
    "data.drop(columns=['Dividends', 'Stock Splits'], inplace=True)\n",
    "\n",
    "# 数据归一化\n",
    "scaler = MinMaxScaler()\n",
    "features = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "data[features] = scaler.fit_transform(data[features])\n",
    "\n",
    "# 定义时间序列长度\n",
    "time_steps =10  # 根据模型需求调整\n",
    "\n",
    "# 创建序列数据\n",
    "def create_sequences(data, time_steps):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - time_steps):\n",
    "        # 获取原始特征数据\n",
    "        X_seq = data.iloc[i:(i + time_steps)][features].values\n",
    "        # 计算新特征：收盘价-开盘价\n",
    "        diff_close_open = X_seq[:, 3] - X_seq[:, 0]\n",
    "        # 计算新特征：今日收盘价-昨日收盘价\n",
    "        diff_close_prev_close = np.diff(X_seq[:, 3], prepend=0)\n",
    "        # 将新特征与原始特征拼接起来\n",
    "        X_seq = np.concatenate([X_seq, diff_close_open.reshape(-1, 1), diff_close_prev_close.reshape(-1, 1)], axis=1)\n",
    "        X.append(X_seq)\n",
    "        y.append(data.iloc[i + time_steps][features].values)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# 创建训练和测试数据\n",
    "train_data = data.loc[:'2022-12-31'] # 训练集包括 2023 年之前和 2024 年之后的数据\n",
    "test_data = data.loc['2023-01-01':]  # 测试集包括 2023 年的数据\n",
    "\n",
    "X_train, y_train = create_sequences(train_data, time_steps)\n",
    "X_test, y_test = create_sequences(test_data, time_steps)\n",
    "\n",
    "# 转换为张量\n",
    "X_train_tensor = torch.Tensor(X_train)\n",
    "y_train_tensor = torch.Tensor(y_train)\n",
    "X_test_tensor = torch.Tensor(X_test)\n",
    "y_test_tensor = torch.Tensor(y_test)\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(TensorDataset(X_train_tensor, y_train_tensor), batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(TensorDataset(X_test_tensor, y_test_tensor), batch_size=64, shuffle=True)\n",
    "\n",
    "# 定义模型\n",
    "class LSTMNet(nn.Module):\n",
    "    def __init__(self, input_size=7, hidden_size=128, num_layers=2, output_size=5):  # 修改 input_size 为 7\n",
    "        super(LSTMNet, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)  # 修改全连接层输入维度为 hidden_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "\n",
    "        out = self.fc(out[:, -1, :])  # 只选择序列的最后一个时间步作为输出\n",
    "\n",
    "        return out\n",
    "\n",
    "# 训练函数\n",
    "def train_model(model, train_loader, val_loader, epochs=100, patience=10):\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    early_stop = False\n",
    "    for epoch in range(epochs):\n",
    "        if early_stop:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for seq, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(seq)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()  # 反向传播\n",
    "            optimizer.step()  # 梯度下降\n",
    "            train_loss += loss.item()\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for seq, labels in val_loader:\n",
    "                outputs = model(seq)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "            val_loss /= len(val_loader)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve == patience:\n",
    "            early_stop = True\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch + 1}, Training Loss: {train_loss:.5f}, Validation Loss: {val_loss:.5f}\")\n",
    "\n",
    "    # 模型评估\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for seq, labels in test_loader:\n",
    "            outputs = model(seq)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "        test_loss /= len(test_loader)\n",
    "    print(f\"Test Loss: {test_loss:.5f}\")\n",
    "\n",
    "# 定义模型\n",
    "model = LSTMNet(input_size=7, hidden_size=128, num_layers=2, output_size=5)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # 使用Adam优化器\n",
    "\n",
    "# 划分验证集\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "total_size = len(train_dataset)\n",
    "val_size = int(0.2 * total_size)\n",
    "train_size = total_size - val_size\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "# 创建 DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# 训练模型\n",
    "train_model(model, train_loader, val_loader, epochs=400, patience=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1d7e349e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T19:49:01.352019Z",
     "start_time": "2024-05-16T19:49:01.344490Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_future(model, start_date, days):\n",
    "    # 将开始日期转换为模型所需的序列数据\n",
    "    start_index = data.index[data.index == start_date][0]\n",
    "    start_index -= time_steps  # 考虑到时间步长\n",
    "\n",
    "    # 准备模型输入\n",
    "    input_seq = torch.Tensor(X_test[start_index:start_index+time_steps]).unsqueeze(0)  # 添加批次维度\n",
    "\n",
    "    # 预测未来days天的数据\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for _ in range(days):\n",
    "            # 使用模型预测下一个时间步\n",
    "            output = model(input_seq)\n",
    "            predictions.append(output.squeeze().tolist())\n",
    "\n",
    "            # 更新输入序列，移除第一个时间步，添加预测值到最后一个时间步\n",
    "            input_seq = torch.cat([input_seq[:, 1:, :], output.unsqueeze(0).unsqueeze(0)], dim=1)\n",
    "\n",
    "    # 将预测值转换为DataFrame，并添加日期索引\n",
    "    prediction_dates = [start_date + timedelta(days=i) for i in range(1, days+1)]\n",
    "    predictions_df = pd.DataFrame(predictions, columns=features, index=prediction_dates)\n",
    "\n",
    "    return predictions_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "67e3b998",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T19:49:07.931975Z",
     "start_time": "2024-05-16T19:49:07.832242Z"
    }
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m days \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m14\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# 进行预测\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_future\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_date_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(predictions)\n",
      "Cell \u001b[0;32mIn[24], line 3\u001b[0m, in \u001b[0;36mpredict_future\u001b[0;34m(model, start_date, days)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_future\u001b[39m(model, start_date, days):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# 将开始日期转换为模型所需的序列数据\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     start_index \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstart_date\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      4\u001b[0m     start_index \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m time_steps  \u001b[38;5;66;03m# 考虑到时间步长\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# 准备模型输入\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/pandas/core/indexes/base.py:5389\u001b[0m, in \u001b[0;36mIndex.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   5386\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(key) \u001b[38;5;129;01mor\u001b[39;00m is_float(key):\n\u001b[1;32m   5387\u001b[0m     \u001b[38;5;66;03m# GH#44051 exclude bool, which would return a 2d ndarray\u001b[39;00m\n\u001b[1;32m   5388\u001b[0m     key \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mcast_scalar_indexer(key)\n\u001b[0;32m-> 5389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgetitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mslice\u001b[39m):\n\u001b[1;32m   5392\u001b[0m     \u001b[38;5;66;03m# This case is separated from the conditional above to avoid\u001b[39;00m\n\u001b[1;32m   5393\u001b[0m     \u001b[38;5;66;03m# pessimization com.is_bool_indexer and ndim checks.\u001b[39;00m\n\u001b[1;32m   5394\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_slice(key)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/pandas/core/arrays/datetimelike.py:381\u001b[0m, in \u001b[0;36mDatetimeLikeArrayMixin.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;124;03mThis getitem defers to the underlying array, which by-definition can\u001b[39;00m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;124;03monly handle list-likes, slices, and integer scalars\u001b[39;00m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;66;03m# Use cast as we know we will get back a DatetimeLikeArray or DTScalar,\u001b[39;00m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;66;03m# but skip evaluating the Union at runtime for performance\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;66;03m# (see https://github.com/pandas-dev/pandas/pull/44624)\u001b[39;00m\n\u001b[0;32m--> 381\u001b[0m result \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnion[Self, DTScalarOrNaT]\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mis_scalar(result):\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/pandas/core/arrays/_mixins.py:284\u001b[0m, in \u001b[0;36mNDArrayBackedExtensionArray.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    280\u001b[0m     key: PositionalIndexer2D,\n\u001b[1;32m    281\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self \u001b[38;5;241m|\u001b[39m Any:\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mis_integer(key):\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;66;03m# fast-path\u001b[39;00m\n\u001b[0;32m--> 284\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ndarray\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    285\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    286\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_box_func(result)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "# 加载最佳模型权重\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "# 设置预测开始日期和预测天数\n",
    "start_date_str = \"2024-05-15\"\n",
    "days = 14\n",
    "\n",
    "# 进行预测\n",
    "predictions = predict_future(model, start_date_str, days)\n",
    "\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cd4ea8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
