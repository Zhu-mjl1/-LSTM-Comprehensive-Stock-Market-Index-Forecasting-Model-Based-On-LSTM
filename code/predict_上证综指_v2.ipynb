{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "fa92a9fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T13:09:04.502290Z",
     "start_time": "2024-05-13T13:08:58.514703Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Training Loss: 0.09467, Validation Loss: 0.08927\n",
      "Epoch 20, Training Loss: 0.04667, Validation Loss: 0.04341\n",
      "Epoch 30, Training Loss: 0.01273, Validation Loss: 0.01148\n",
      "Epoch 40, Training Loss: 0.00333, Validation Loss: 0.00302\n",
      "Epoch 50, Training Loss: 0.00236, Validation Loss: 0.00212\n",
      "Epoch 60, Training Loss: 0.00208, Validation Loss: 0.00180\n",
      "Epoch 70, Training Loss: 0.00183, Validation Loss: 0.00153\n",
      "Epoch 80, Training Loss: 0.00163, Validation Loss: 0.00131\n",
      "Epoch 90, Training Loss: 0.00147, Validation Loss: 0.00114\n",
      "Epoch 100, Training Loss: 0.00136, Validation Loss: 0.00101\n",
      "Epoch 110, Training Loss: 0.00125, Validation Loss: 0.00090\n",
      "Epoch 120, Training Loss: 0.00120, Validation Loss: 0.00082\n",
      "Epoch 130, Training Loss: 0.00111, Validation Loss: 0.00078\n",
      "Epoch 140, Training Loss: 0.00108, Validation Loss: 0.00073\n",
      "Epoch 150, Training Loss: 0.00103, Validation Loss: 0.00070\n",
      "Epoch 160, Training Loss: 0.00100, Validation Loss: 0.00067\n",
      "Epoch 170, Training Loss: 0.00099, Validation Loss: 0.00065\n",
      "Epoch 180, Training Loss: 0.00094, Validation Loss: 0.00064\n",
      "Epoch 190, Training Loss: 0.00091, Validation Loss: 0.00061\n",
      "Epoch 200, Training Loss: 0.00088, Validation Loss: 0.00059\n",
      "Epoch 210, Training Loss: 0.00085, Validation Loss: 0.00058\n",
      "Epoch 220, Training Loss: 0.00087, Validation Loss: 0.00056\n",
      "Epoch 230, Training Loss: 0.00083, Validation Loss: 0.00055\n",
      "Epoch 240, Training Loss: 0.00079, Validation Loss: 0.00054\n",
      "Epoch 250, Training Loss: 0.00080, Validation Loss: 0.00054\n",
      "Epoch 260, Training Loss: 0.00075, Validation Loss: 0.00053\n",
      "Epoch 270, Training Loss: 0.00074, Validation Loss: 0.00052\n",
      "Epoch 280, Training Loss: 0.00073, Validation Loss: 0.00052\n",
      "Epoch 290, Training Loss: 0.00071, Validation Loss: 0.00051\n",
      "Epoch 300, Training Loss: 0.00070, Validation Loss: 0.00050\n",
      "Epoch 310, Training Loss: 0.00070, Validation Loss: 0.00050\n",
      "Epoch 320, Training Loss: 0.00069, Validation Loss: 0.00049\n",
      "Epoch 330, Training Loss: 0.00068, Validation Loss: 0.00049\n",
      "Epoch 340, Training Loss: 0.00067, Validation Loss: 0.00049\n",
      "Early stopping at epoch 348\n",
      "Future Predicted Prices:\n",
      "2024-05-13: Open: 3161.53, High: 3188.74, Low: 3121.90, Close: 3147.17,\n",
      "2024-05-14: Open: 3158.68, High: 3170.90, Low: 3111.20, Close: 3146.79,\n",
      "2024-05-15: Open: 3140.01, High: 3168.96, Low: 3109.34, Close: 3157.59,\n",
      "2024-05-16: Open: 3156.38, High: 3199.65, Low: 3119.15, Close: 3176.97,\n",
      "2024-05-17: Open: 3154.74, High: 3190.94, Low: 3127.14, Close: 3159.61,\n",
      "2024-05-18: Open: 3158.12, High: 3194.92, Low: 3145.22, Close: 3163.07,\n",
      "2024-05-19: Open: 3177.73, High: 3211.08, Low: 3155.10, Close: 3175.55,\n",
      "2024-05-20: Open: 3173.74, High: 3197.82, Low: 3149.88, Close: 3171.04,\n",
      "2024-05-21: Open: 3178.86, High: 3210.26, Low: 3154.67, Close: 3188.98,\n",
      "2024-05-22: Open: 3191.87, High: 3226.46, Low: 3163.60, Close: 3199.78,\n",
      "2024-05-23: Open: 3190.58, High: 3222.66, Low: 3165.99, Close: 3198.39,\n",
      "2024-05-24: Open: 3194.21, High: 3228.23, Low: 3171.21, Close: 3203.66,\n",
      "2024-05-25: Open: 3202.63, High: 3234.04, Low: 3177.88, Close: 3208.03,\n",
      "2024-05-26: Open: 3204.85, High: 3237.40, Low: 3180.52, Close: 3211.71,\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import yfinance as yf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# 加载数据\n",
    "ticker = \"000001.SS\"\n",
    "stock = yf.Ticker(ticker)\n",
    "data = stock.history(start=\"2010-01-01\", end=\"2024-05-10\")\n",
    "\n",
    "# 过滤数据，只包含交易日\n",
    "data = data[data['Volume'] > 0]\n",
    "data.drop(columns=['Dividends', 'Stock Splits'], inplace=True)\n",
    "\n",
    "# 数据归一化\n",
    "scaler = MinMaxScaler()\n",
    "features = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "data[features] = scaler.fit_transform(data[features])\n",
    "\n",
    "# 定义时间序列长度\n",
    "time_steps =10  # 根据模型需求调整\n",
    "\n",
    "# 创建序列数据\n",
    "def create_sequences(data, time_steps):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - time_steps):\n",
    "        X.append(data.iloc[i:(i + time_steps)][features].values)\n",
    "        y.append(data.iloc[i + time_steps][features].values)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# 创建训练和测试数据\n",
    "train_data = data.loc[:'2022-12-31'] # 训练集包括 2023 年之前和 2024 年之后的数据\n",
    "test_data = data.loc['2023-01-01':]  # 测试集包括 2023 年的数据\n",
    "\n",
    "X_train, y_train = create_sequences(train_data, time_steps)\n",
    "X_test, y_test = create_sequences(test_data, time_steps)\n",
    "\n",
    "# 转换为张量\n",
    "X_train_tensor = torch.Tensor(X_train)\n",
    "y_train_tensor = torch.Tensor(y_train)\n",
    "X_test_tensor = torch.Tensor(X_test)\n",
    "y_test_tensor = torch.Tensor(y_test)\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(TensorDataset(X_train_tensor, y_train_tensor), batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(TensorDataset(X_test_tensor, y_test_tensor), batch_size=64, shuffle=True)\n",
    "\n",
    "# 定义模型\n",
    "\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size // 2)\n",
    "        self.fc3 = nn.Linear(hidden_size // 2, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "input_size = time_steps * len(features)\n",
    "hidden_size = 128\n",
    "output_size = len(features)\n",
    "\n",
    "model = SimpleNet(input_size, hidden_size, output_size)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5, weight_decay=3e-5)\n",
    "\n",
    "# 训练函数\n",
    "def train_model(model, train_loader, val_loader, epochs=100, patience=10):\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0.2\n",
    "\n",
    "    early_stop = False\n",
    "    for epoch in range(epochs):\n",
    "        if early_stop:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for seq, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            seq = seq.view(seq.shape[0], -1)\n",
    "            outputs = model(seq)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for seq, labels in val_loader:\n",
    "                seq = seq.view(seq.shape[0], -1)\n",
    "                outputs = model(seq)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "            val_loss /= len(val_loader)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve == patience:\n",
    "            early_stop = True\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch + 1}, Training Loss: {train_loss:.5f}, Validation Loss: {val_loss:.5f}\")\n",
    "\n",
    "# 划分验证集\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "total_size = len(train_dataset)\n",
    "val_size = int(0.2 * total_size)\n",
    "train_size = total_size - val_size\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "# 创建 DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# 训练模型\n",
    "train_model(model, train_loader, val_loader, epochs=400, patience=10)\n",
    "\n",
    "# 使用模型进行预测\n",
    "def pre(days):\n",
    "    future_predictions = []\n",
    "    with torch.no_grad():\n",
    "        current_seq = X_test_tensor[-1].reshape(1, -1)\n",
    "        for _ in range(days):\n",
    "            prediction = model(current_seq).detach()\n",
    "            future_predictions.append(prediction.numpy())\n",
    "            next_seq = torch.cat((current_seq[:, len(features):], prediction), 1)\n",
    "            current_seq = next_seq\n",
    "\n",
    "    future_predictions = np.vstack(future_predictions)\n",
    "    predicted_prices = scaler.inverse_transform(future_predictions)\n",
    "\n",
    "    start_date = datetime.strptime(\"2024-05-13\", \"%Y-%m-%d\")\n",
    "    print(\"Future Predicted Prices:\")\n",
    "    for i, prices in enumerate(predicted_prices):\n",
    "        date = start_date + timedelta(days=i)\n",
    "        print(f\"{date.date()}: Open: {prices[0]:.2f}, High: {prices[1]:.2f}, Low: {prices[2]:.2f}, Close: {prices[3]:.2f},\")\n",
    "pre(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3362a8ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
