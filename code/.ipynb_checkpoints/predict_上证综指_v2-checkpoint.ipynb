{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6ac4ef40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T13:19:38.359692Z",
     "start_time": "2024-05-16T13:19:24.526709Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Training Loss: 0.00087, Validation Loss: 0.00074\n",
      "Epoch 20, Training Loss: 0.00056, Validation Loss: 0.00047\n",
      "Epoch 30, Training Loss: 0.00049, Validation Loss: 0.00042\n",
      "Epoch 40, Training Loss: 0.00046, Validation Loss: 0.00046\n",
      "Epoch 50, Training Loss: 0.00049, Validation Loss: 0.00041\n",
      "Early stopping at epoch 53\n",
      "Test Loss: 0.00057\n"
     ]
    }
   ],
   "source": [
    "# 加载数据\n",
    "ticker = \"000001.SS\"\n",
    "stock = yf.Ticker(ticker)\n",
    "data = stock.history(start=\"2010-01-01\", end=\"2024-05-10\")\n",
    "\n",
    "# 过滤数据，只包含交易日\n",
    "data = data[data['Volume'] > 0]\n",
    "data.drop(columns=['Dividends', 'Stock Splits'], inplace=True)\n",
    "\n",
    "# 数据归一化\n",
    "scaler = MinMaxScaler()\n",
    "features = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "data[features] = scaler.fit_transform(data[features])\n",
    "\n",
    "# 定义时间序列长度\n",
    "time_steps =10  # 根据模型需求调整\n",
    "\n",
    "# 创建序列数据\n",
    "def create_sequences(data, time_steps):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - time_steps):\n",
    "        # 获取原始特征数据\n",
    "        X_seq = data.iloc[i:(i + time_steps)][features].values\n",
    "        # 计算新特征：收盘价-开盘价\n",
    "        diff_close_open = X_seq[:, 3] - X_seq[:, 0]\n",
    "        # 计算新特征：今日收盘价-昨日收盘价\n",
    "        diff_close_prev_close = np.diff(X_seq[:, 3], prepend=0)\n",
    "        # 将新特征与原始特征拼接起来\n",
    "        X_seq = np.concatenate([X_seq, diff_close_open.reshape(-1, 1), diff_close_prev_close.reshape(-1, 1)], axis=1)\n",
    "        X.append(X_seq)\n",
    "        y.append(data.iloc[i + time_steps][features].values)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# 创建训练和测试数据\n",
    "train_data = data.loc[:'2022-12-31'] # 训练集包括 2023 年之前和 2024 年之后的数据\n",
    "test_data = data.loc['2023-01-01':]  # 测试集包括 2023 年的数据\n",
    "\n",
    "X_train, y_train = create_sequences(train_data, time_steps)\n",
    "X_test, y_test = create_sequences(test_data, time_steps)\n",
    "\n",
    "# 转换为张量\n",
    "X_train_tensor = torch.Tensor(X_train)\n",
    "y_train_tensor = torch.Tensor(y_train)\n",
    "X_test_tensor = torch.Tensor(X_test)\n",
    "y_test_tensor = torch.Tensor(y_test)\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(TensorDataset(X_train_tensor, y_train_tensor), batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(TensorDataset(X_test_tensor, y_test_tensor), batch_size=64, shuffle=True)\n",
    "\n",
    "# 定义模型\n",
    "class LSTMNet(nn.Module):\n",
    "    def __init__(self, input_size=7, hidden_size=128, num_layers=2, output_size=5):  # 修改 input_size 为 7\n",
    "        super(LSTMNet, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)  # 修改全连接层输入维度为 hidden_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "\n",
    "        out = self.fc(out[:, -1, :])  # 只选择序列的最后一个时间步作为输出\n",
    "\n",
    "        return out\n",
    "\n",
    "# 训练函数\n",
    "def train_model(model, train_loader, val_loader, epochs=100, patience=10):\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    early_stop = False\n",
    "    for epoch in range(epochs):\n",
    "        if early_stop:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for seq, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(seq)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()  # 反向传播\n",
    "            optimizer.step()  # 梯度下降\n",
    "            train_loss += loss.item()\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for seq, labels in val_loader:\n",
    "                outputs = model(seq)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "            val_loss /= len(val_loader)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve == patience:\n",
    "            early_stop = True\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch + 1}, Training Loss: {train_loss:.5f}, Validation Loss: {val_loss:.5f}\")\n",
    "\n",
    "    # 模型评估\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for seq, labels in test_loader:\n",
    "            outputs = model(seq)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "        test_loss /= len(test_loader)\n",
    "    print(f\"Test Loss: {test_loss:.5f}\")\n",
    "\n",
    "# 定义模型\n",
    "model = LSTMNet(input_size=7, hidden_size=128, num_layers=2, output_size=5)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # 使用Adam优化器\n",
    "\n",
    "# 划分验证集\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "total_size = len(train_dataset)\n",
    "val_size = int(0.2 * total_size)\n",
    "train_size = total_size - val_size\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "# 创建 DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# 训练模型\n",
    "train_model(model, train_loader, val_loader, epochs=400, patience=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d636bead",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T13:42:12.840776Z",
     "start_time": "2024-05-16T13:42:12.833618Z"
    }
   },
   "outputs": [],
   "source": [
    "def pre(start_date, days):\n",
    "    future_predictions = []\n",
    "    with torch.no_grad():\n",
    "        # 选择足够多的历史数据作为初始序列\n",
    "        time_steps = days * 5  # 选择预测天数的两倍作为初始序列的时间步数\n",
    "        current_seq = X_test_tensor[-time_steps:].unsqueeze(0)  # 增加批次维度\n",
    "        for _ in range(days):\n",
    "            # 计算新特征：收盘价-开盘价\n",
    "            diff_close_open = current_seq[:, :, 3] - current_seq[:, :, 0]  # 收盘价在第3列，开盘价在第0列\n",
    "            diff_close_open = diff_close_open.unsqueeze(-1)  # 添加一个维度以与LSTM输出匹配\n",
    "\n",
    "            # 计算新特征：今日收盘价-昨日收盘价\n",
    "            diff_close_prev_close = current_seq[:, :, :, 3][:, :, 1:] - current_seq[:, :, :, 3][:, :, :-1]\n",
    "            diff_close_prev_close = diff_close_prev_close.unsqueeze(-1)\n",
    "\n",
    "            # 将新特征与原始特征拼接起来\n",
    "            current_seq = torch.cat((current_seq, diff_close_open, diff_close_prev_close), dim=-1)\n",
    "\n",
    "            prediction = model(current_seq)\n",
    "            future_predictions.append(prediction.numpy())\n",
    "            # 更新当前序列，将预测值添加到末尾，并移除最早的数据\n",
    "            current_seq = torch.cat((current_seq[:, 1:, :, :], prediction.unsqueeze(1)), 1)\n",
    "\n",
    "    future_predictions = np.vstack(future_predictions)\n",
    "    predicted_prices = scaler.inverse_transform(future_predictions)\n",
    "\n",
    "    start_date = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "    print(\"Future Predicted Prices:\")\n",
    "    for i, prices in enumerate(predicted_prices):\n",
    "        date = start_date + timedelta(days=i)\n",
    "        print(f\"{date.date()}: Open: {prices[0]:.2f}, High: {prices[1]:.2f}, Low: {prices[2]:.2f}, Close: {prices[3]:.2f}, Volume: {prices[4]:.2f},\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3362a8ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T13:42:17.062156Z",
     "start_time": "2024-05-16T13:42:17.025016Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 3. Expected size 10 but got size 7 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[100], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpre\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m2024-05-16\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[99], line 17\u001b[0m, in \u001b[0;36mpre\u001b[0;34m(start_date, days)\u001b[0m\n\u001b[1;32m     14\u001b[0m diff_close_prev_close \u001b[38;5;241m=\u001b[39m diff_close_prev_close\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# 将新特征与原始特征拼接起来\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m current_seq \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_seq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiff_close_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiff_close_prev_close\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m prediction \u001b[38;5;241m=\u001b[39m model(current_seq)\n\u001b[1;32m     20\u001b[0m future_predictions\u001b[38;5;241m.\u001b[39mappend(prediction\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 3. Expected size 10 but got size 7 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "pre(\"2024-05-16\", 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22f66ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4afea2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
